{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_path = 'skeleton-reality-data/re_skeleton_raw_1.txt'\n",
    "with open(skeleton_path, 'r') as f:\n",
    "    skeleton_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_NAMES = ['Wave','Hammer','Smash','Catch','Forward Punch','Throw','Draw X','Draw Tick','Draw Circle',\n",
    "               'Clapping Hand','Two hand Wave','Side Boxing','Bend','Forward Kick','Side Kick','Jogging',\n",
    "               'Tennis Swing','Tennis Serve','Golf Swing','Pickup&throw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From frame 30th to 160th\n",
    "action_11 = skeleton_list[610:775]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(action_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.186174 -0.236540 3.022136 0.191174 -0.184076 3.079624 0.210051 0.146475 3.095182 0.207977 0.314886 3.115148 0.042236 0.117579 3.093050 -0.121019 0.262842 3.056628 -0.248450 0.414940 3.006071 -0.299031 0.495962 2.976345 0.359864 0.025460 3.070377 0.406240 -0.224912 3.018939 0.389909 -0.419009 2.931433 0.369122 -0.508232 2.898142 0.108877 -0.300519 3.005601 0.069882 -0.730583 2.953170 0.042826 -1.062970 2.918303 0.013056 -1.126038 2.863394 0.254631 -0.314573 3.003804 0.288527 -0.728296 2.961001 0.305925 -1.074903 2.941937 0.312165 -1.118699 2.892645 -0.006577 0.991491 0.130009 0.764766 \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_11[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(action_11)):\n",
    "    action_11[i] = action_11[i].rstrip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.186174 -0.236540 3.022136 0.191174 -0.184076 3.079624 0.210051 0.146475 3.095182 0.207977 0.314886 3.115148 0.042236 0.117579 3.093050 -0.121019 0.262842 3.056628 -0.248450 0.414940 3.006071 -0.299031 0.495962 2.976345 0.359864 0.025460 3.070377 0.406240 -0.224912 3.018939 0.389909 -0.419009 2.931433 0.369122 -0.508232 2.898142 0.108877 -0.300519 3.005601 0.069882 -0.730583 2.953170 0.042826 -1.062970 2.918303 0.013056 -1.126038 2.863394 0.254631 -0.314573 3.003804 0.288527 -0.728296 2.961001 0.305925 -1.074903 2.941937 0.312165 -1.118699 2.892645 -0.006577 0.991491 0.130009 0.764766 '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_11[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(action_11)):\n",
    "    action_11[i] = action_11[i].split(' ')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(action_11)):\n",
    "    action_11[i] = [float(coor) for coor in action_11[i]]\n",
    "    action_11[i] = action_11[i][:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns4_11 = np.array([9,11,13,20])\n",
    "Ns4_11 = Ns4_11-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = [], [], []\n",
    "for i in range(len(action_11)):\n",
    "    for j in range(len(action_11[i])):\n",
    "        if j%3 == 0:\n",
    "            x.append(action_11[i][j])\n",
    "        elif j%3 == 1:\n",
    "            y.append(action_11[i][j])\n",
    "        elif j%3 == 2:\n",
    "            z.append(action_11[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(x)\n",
    "y = np.asarray(y)\n",
    "z = np.asarray(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3300,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_skeleton(X):\n",
    "    noFrames = int(X.shape[0]/20)\n",
    "    reshaped_X = []\n",
    "    for i in range(20):\n",
    "        reshaped_X.append([X[j] for j in range(i, X.shape[0], 20)])\n",
    "    reshaped_X = np.asarray(reshaped_X)\n",
    "    return reshaped_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reshape_skeleton(x)\n",
    "Y = reshape_skeleton(y)\n",
    "Z = reshape_skeleton(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[Ns4_11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y[Ns4_11]\n",
    "Z = Z[Ns4_11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from norm import *\n",
    "from MostJoints.getMostInformativeJoints import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateCovarianceMat(X, Y, Z, T, nLevels, overlap = False, timeVar=True):\n",
    "    nFrames = X.shape[0]\n",
    "    nJoins = X.shape[1]\n",
    "    assert Y.shape[0] == nFrames\n",
    "    assert Z.shape[0] == nFrames\n",
    "    assert T.shape[0] == nFrames\n",
    "    assert Y.shape[1] == nJoins\n",
    "    assert Z.shape[1] == nJoins\n",
    "\n",
    "    # Normalize skeleton coordinators\n",
    "\n",
    "    normX = normCord(X)\n",
    "    normY = normCord(Y)\n",
    "    normZ = normCord(Z)\n",
    "    normT = normSeT(T)\n",
    "\n",
    "    # Create a list of full covariance matrices\n",
    "    fullCovMats = [[] for i in range(nLevels)]\n",
    "    covMats = [[] for i in range(nLevels)]\n",
    "\n",
    "    if timeVar:\n",
    "        sizeMatrix = nJoins*3+1\n",
    "    else:\n",
    "        sizeMatrix = nJoins*3\n",
    "\n",
    "    listIdxMatrix = getValueMatrix(sizeMatrix) # get half of covariance matrix indexes\n",
    "\n",
    "\n",
    "    for l in range(1,nLevels+1):\n",
    "        # Compute covariance matrixes for each level\n",
    "        nofMats = 2**(l-1)\n",
    "        sizeWindow = 1/nofMats\n",
    "        stepWindow = sizeWindow\n",
    "        if overlap:\n",
    "            stepWindow = stepWindow/2\n",
    "            nofMats = nofMats*2-1\n",
    "        startFrameTimes = [stepWindow*i for i in range(nofMats)]\n",
    "        fullCovMats[l-1] = [[] for i in range(nofMats)]\n",
    "        covMats[l-1] = [[] for i in range(nofMats)]\n",
    "        for i in range(len(startFrameTimes)):\n",
    "            startTime = startFrameTimes[i]\n",
    "            endTime = startFrameTimes[i] + sizeWindow + 2*np.finfo(float).eps\n",
    "            sliceInds = [j for j in range(T.shape[0]) if normT[j] >= startTime and normT[j] < endTime]\n",
    "            sliceX = normX[sliceInds, :]\n",
    "            sliceY = normY[sliceInds, :]\n",
    "            sliceZ = normZ[sliceInds, :]\n",
    "            sliceT = normT[sliceInds]\n",
    "            if not timeVar:\n",
    "                sliceVars = np.concatenate((np.concatenate((sliceX,sliceY), axis=1), sliceZ), axis=1)\n",
    "            else:\n",
    "                sliceVars = np.concatenate((np.concatenate((sliceX, sliceY), axis=1), np.concatenate((sliceZ, sliceT), axis=1)), axis=1)\n",
    "            covarianceMat = np.cov(sliceVars.T)\n",
    "            fullCovMats[l-1][i] = covarianceMat\n",
    "            # Get half of covarianceMat and save it as a vector (1-D matrix)\n",
    "            one_half_vector = []\n",
    "            mask = np.zeros_like(covarianceMat, dtype=np.bool)\n",
    "            mask[np.triu_indices_from(mask)] = True\n",
    "            for row in range(covarianceMat.shape[0]):\n",
    "                for column in range(covarianceMat.shape[0]):\n",
    "                    if mask[row][column] == True:\n",
    "                        one_half_vector.append(covarianceMat[row][column])\n",
    "            covMats[l-1][i] = np.asarray(one_half_vector)\n",
    "        covMats[l-1] = np.asarray(covMats[l-1])\n",
    "        \n",
    "    covMats = np.asarray(covMats)\n",
    "    vec = np.empty(0)\n",
    "    for i in range(covMats.shape[0]):\n",
    "        for j in range(covMats[i].shape[0]):\n",
    "            vec = np.hstack((vec, covMats[i][j]))\n",
    "    return fullCovMats, vec\n",
    "\n",
    "def get_covariance_vector(x,y,z,t):\n",
    "    fullCovmat, vec_covMat = calculateCovarianceMat(x.T, y.T, z.T, t, nLevels=3, overlap=True, timeVar=False)\n",
    "    return vec_covMat\n",
    "\n",
    "def make_preprocessed_training_data():\n",
    "    T = np.arange(1, X.shape[1]+1).T\n",
    "    vec_covMat = get_covariance_vector(X,Y,Z,T)\n",
    "    return vec_covMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('models/as2_svm_model.pkl', 'rb')\n",
    "model = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_covMat = make_preprocessed_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "X_test.append(vec_covMat)\n",
    "X_test = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred[0])\n",
    "if y_pred[0] == 14:\n",
    "    y_pred[0] == 1\n",
    "elif y_pred[0] == 13:\n",
    "    y_pred[0] == 2\n",
    "# print(\"Acting : \", ACTION_NAMES[y_pred[0]-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
