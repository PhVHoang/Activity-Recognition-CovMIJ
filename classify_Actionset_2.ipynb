{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from norm import *\n",
    "from utils import *\n",
    "from MostJoints.getMostInformativeJoints import *\n",
    "import os\n",
    "from itertools import chain\n",
    "import setting\n",
    "import pickle\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns4_as2_list = np.array([[9,11,13,2],\n",
    "[0,0,0,0],\n",
    "[0,0,0,0],\n",
    "[9,11,13,20],\n",
    "[0,0,0,0],\n",
    "[0,0,0,0],\n",
    "[9,11,13,2],\n",
    "[9,11,13,2],\n",
    "[9,11,13,2],\n",
    "[0,0,0,0],\n",
    "[10,11,12,13],\n",
    "[11,13,12,9],\n",
    "[0,0,0,0],\n",
    "[17,19,15,12],\n",
    "[0,0,0,0],\n",
    "[0,0,0,0],\n",
    "[0,0,0,0],\n",
    "[0,0,0,0],\n",
    "[0,0,0,0],\n",
    "[0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns4_as2_list = Ns4_as2_list-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/'\n",
    "ACTION_SETS_PATH = 'actionsets/'\n",
    "ACTION_SETS  = ['actionsets/ActionSet1.txt', 'actionsets/ActionSet2.txt', 'actionsets/ActionSet3.txt']\n",
    "ACTION_NAMES = ['Wave','Hammer','Smash','Catch','Forward Punch','Throw','Draw X','Draw Tick','Draw ',\n",
    "               'Circle','Clapping Hand','Two hand Wave','Side Boxing','Bend','Forward Kick','Side Kick','Jogging',\n",
    "               'Tennis Swing','Tennis Serve','Golf Swing','Pickup&throw']\n",
    "TRAINING_SUBJECTS = ['s01','s03','s05','s07','s09']\n",
    "TESTING_SUBJECTS = ['s02','s04','s06','s08','s10']\n",
    "\n",
    "with open(ACTION_SETS_PATH + 'ActionSet2.txt', 'r') as f:\n",
    "    as3_names = f.readlines()\n",
    "for i in range(len(as3_names)):\n",
    "    as3_names[i] = as3_names[i].rstrip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_as3_names = [as3_names[i] for i in range(len(as3_names)) if as3_names[i][4:7] in TRAINING_SUBJECTS]\n",
    "test_as3_names = [as3_names[i] for i in range(len(as3_names)) if as3_names[i][4:7] in TESTING_SUBJECTS]\n",
    "train_as3_names = [train_as3_names[i] + '_skeleton3D.txt' for i in range(len(train_as3_names))]\n",
    "test_as3_names = [test_as3_names[i] + '_skeleton3D.txt' for i in range(len(test_as3_names))]\n",
    "as3_names = [as3_names[i] + '_skeleton3D.txt' for i in range(len(as3_names))]\n",
    "train_as3_names = sorted(train_as3_names)\n",
    "test_as3_names = sorted(test_as3_names)\n",
    "as3_names = sorted(as3_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_skeleton(X):\n",
    "    noFrames = int(X.shape[0]/setting.NUMBER_OF_JOINTS)\n",
    "    reshaped_X = []\n",
    "    for i in range(setting.NUMBER_OF_JOINTS):\n",
    "        reshaped_X.append([X[j] for j in range(i, X.shape[0], 20)])\n",
    "    reshaped_X = np.asarray(reshaped_X)\n",
    "    return reshaped_X\n",
    "def get_MIJ_matrices(filename):\n",
    "    \n",
    "    action_label = int(filename[1:3])\n",
    "    \n",
    "    with open('data/' + filename, 'r') as f:\n",
    "        skeleton_matrix = [line.rstrip('\\n') for line in f]\n",
    "    for j in range(len(skeleton_matrix)):\n",
    "        skeleton_matrix[j] = [float(coord) for coord in skeleton_matrix[j].split(' ')]\n",
    "    \n",
    "    skeleton_matrix = np.asarray(skeleton_matrix)\n",
    "    noFrames = int(skeleton_matrix.shape[0]/setting.NUMBER_OF_JOINTS)\n",
    "    x = skeleton_matrix[:,0]\n",
    "    y = skeleton_matrix[:,1]\n",
    "    z = skeleton_matrix[:,2]\n",
    "    \n",
    "    x = reshape_skeleton(x)\n",
    "    y = reshape_skeleton(y)\n",
    "    z = reshape_skeleton(z)\n",
    "    t = np.arange(1, noFrames+1).T\n",
    "    \n",
    "    x = x[Ns4_as2_list[action_label-1]]\n",
    "    y = y[Ns4_as2_list[action_label-1]]\n",
    "    z = z[Ns4_as2_list[action_label-1]]\n",
    "\n",
    "    return x,y,z,t\n",
    "def calculateCovarianceMat(X, Y, Z, T, nLevels, overlap = False, timeVar=True):\n",
    "    nFrames = X.shape[0]\n",
    "    nJoins = X.shape[1]\n",
    "    assert Y.shape[0] == nFrames\n",
    "    assert Z.shape[0] == nFrames\n",
    "    assert T.shape[0] == nFrames\n",
    "    assert Y.shape[1] == nJoins\n",
    "    assert Z.shape[1] == nJoins\n",
    "\n",
    "    # Normalize skeleton coordinators\n",
    "\n",
    "    normX = normCord(X)\n",
    "    normY = normCord(Y)\n",
    "    normZ = normCord(Z)\n",
    "    normT = normSeT(T)\n",
    "\n",
    "    # Create a list of full covariance matrices\n",
    "    fullCovMats = [[] for i in range(nLevels)]\n",
    "    covMats = [[] for i in range(nLevels)]\n",
    "\n",
    "    if timeVar:\n",
    "        sizeMatrix = nJoins*3+1\n",
    "    else:\n",
    "        sizeMatrix = nJoins*3\n",
    "\n",
    "    listIdxMatrix = getValueMatrix(sizeMatrix) # get half of covariance matrix indexes\n",
    "\n",
    "\n",
    "    for l in range(1,nLevels+1):\n",
    "        # Compute covariance matrixes for each level\n",
    "        nofMats = 2**(l-1)\n",
    "        sizeWindow = 1/nofMats\n",
    "        stepWindow = sizeWindow\n",
    "        if overlap:\n",
    "            stepWindow = stepWindow/2\n",
    "            nofMats = nofMats*2-1\n",
    "        startFrameTimes = [stepWindow*i for i in range(nofMats)]\n",
    "        fullCovMats[l-1] = [[] for i in range(nofMats)]\n",
    "        covMats[l-1] = [[] for i in range(nofMats)]\n",
    "        for i in range(len(startFrameTimes)):\n",
    "            startTime = startFrameTimes[i]\n",
    "            endTime = startFrameTimes[i] + sizeWindow + 2*np.finfo(float).eps\n",
    "            sliceInds = [j for j in range(T.shape[0]) if normT[j] >= startTime and normT[j] < endTime]\n",
    "            sliceX = normX[sliceInds, :]\n",
    "            sliceY = normY[sliceInds, :]\n",
    "            sliceZ = normZ[sliceInds, :]\n",
    "            sliceT = normT[sliceInds]\n",
    "            if not timeVar:\n",
    "                sliceVars = np.concatenate((np.concatenate((sliceX,sliceY), axis=1), sliceZ), axis=1)\n",
    "            else:\n",
    "                sliceVars = np.concatenate((np.concatenate((sliceX, sliceY), axis=1), np.concatenate((sliceZ, sliceT), axis=1)), axis=1)\n",
    "            covarianceMat = np.cov(sliceVars.T)\n",
    "            fullCovMats[l-1][i] = covarianceMat\n",
    "            # Get half of covarianceMat and save it as a vector (1-D matrix)\n",
    "            one_half_vector = []\n",
    "            mask = np.zeros_like(covarianceMat, dtype=np.bool)\n",
    "            mask[np.triu_indices_from(mask)] = True\n",
    "            for row in range(covarianceMat.shape[0]):\n",
    "                for column in range(covarianceMat.shape[0]):\n",
    "                    if mask[row][column] == True:\n",
    "                        one_half_vector.append(covarianceMat[row][column])\n",
    "            covMats[l-1][i] = np.asarray(one_half_vector)\n",
    "        covMats[l-1] = np.asarray(covMats[l-1])\n",
    "        \n",
    "    covMats = np.asarray(covMats)\n",
    "    vec = np.empty(0)\n",
    "    for i in range(covMats.shape[0]):\n",
    "        for j in range(covMats[i].shape[0]):\n",
    "            vec = np.hstack((vec, covMats[i][j]))\n",
    "    return fullCovMats, vec\n",
    "\n",
    "def get_covariance_vector(x,y,z,t):\n",
    "    fullCovmat, vec_covMat = calculateCovarianceMat(x.T, y.T, z.T, t, nLevels=3, overlap=True, timeVar=False)\n",
    "    return vec_covMat\n",
    "\n",
    "def make_preprocessed_training_data(filenames):\n",
    "    X_train, y_train = [], []\n",
    "    for i in range(len(filenames)):\n",
    "        x, y, z, t = get_MIJ_matrices(filenames[i])\n",
    "        vec_covMat = get_covariance_vector(x,y,z,t)\n",
    "        label = int(filenames[i][1:3])\n",
    "        X_train.append(vec_covMat)\n",
    "        y_train.append(label)\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = make_preprocessed_training_data(train_as3_names)\n",
    "model = OneVsRestClassifier(LinearSVC(random_state=0)).fit(X_train, y_train)\n",
    "model_name = 'as2_svm_model.pkl'\n",
    "with open(model_name, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "X_test, y_test = make_preprocessed_training_data(test_as3_names)\n",
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.96428571428571\n"
     ]
    }
   ],
   "source": [
    "def get_acc(y_test, y_hat):\n",
    "    count = 0\n",
    "    for i in range(y_test.shape[0]):\n",
    "        if y_test[i] == y_hat[i]:\n",
    "            count += 1\n",
    "    acc = (count/y_test.shape[0])*100\n",
    "    return acc\n",
    "print(get_acc(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9196428571428571"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_hat, average='micro')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "skeleton_path = 'skeleton-reality-data/re_skeleton_raw_1.txt'\n",
    "model_SVC = OneVsRestClassifier(SVC(probability=True, random_state=0)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]\n",
      "[0.00175423 0.08890005 0.01055037 0.01278852 0.02384877 0.00348018\n",
      " 0.41311504 0.44556284]\n"
     ]
    }
   ],
   "source": [
    "with open(skeleton_path, 'r') as f:\n",
    "    skeleton_list = f.readlines()\n",
    "\n",
    "action_11 = skeleton_list[430:610]\n",
    "for i in range(len(action_11)):\n",
    "    action_11[i] = action_11[i].rstrip('\\n')\n",
    "for i in range(len(action_11)):\n",
    "    action_11[i] = action_11[i].split(' ')[:-1]\n",
    "\n",
    "for i in range(len(action_11)):\n",
    "    action_11[i] = [float(coor) for coor in action_11[i]]\n",
    "    action_11[i] = action_11[i][:60]\n",
    "\n",
    "    \n",
    "Ns4_11 = np.array([9,11,13,2])\n",
    "Ns4_11 = Ns4_11-1\n",
    "\n",
    "x,y,z = [], [], []\n",
    "for i in range(len(action_11)):\n",
    "    for j in range(len(action_11[i])):\n",
    "        if j%3 == 0:\n",
    "            x.append(action_11[i][j])\n",
    "        elif j%3 == 1:\n",
    "            y.append(action_11[i][j])\n",
    "        elif j%3 == 2:\n",
    "            z.append(action_11[i][j])\n",
    "x = np.asarray(x)\n",
    "y = np.asarray(y)\n",
    "z = np.asarray(z)\n",
    "X = reshape_skeleton(x)\n",
    "Y = reshape_skeleton(y)\n",
    "Z = reshape_skeleton(z)\n",
    "\n",
    "X = X[Ns4_11]\n",
    "Y = Y[Ns4_11]\n",
    "Z = Z[Ns4_11]\n",
    "\n",
    "def make_preprocessed_reality_data():\n",
    "    T = np.arange(1, X.shape[1]+1).T\n",
    "    vec_covMat = get_covariance_vector(X,Y,Z,T)\n",
    "    return vec_covMat\n",
    "\n",
    "vec_covMat = make_preprocessed_reality_data()\n",
    "X_reality_test = []\n",
    "X_reality_test.append(vec_covMat)\n",
    "X_reality_test = np.asarray(X_reality_test)\n",
    "y_pred_proba = model_SVC.predict_proba(X_reality_test)\n",
    "y_pred = model_SVC.predict(X_reality_test)\n",
    "print(y_pred)\n",
    "print(min(y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_SVC = model_SVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 12,  4,  1,  8,  1,  1,  1,  1,  1,  1,  1,  4,  4,  4,  7,  8,\n",
       "        4, 12,  4,  4,  4,  4,  4,  7,  7,  7,  8,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  9,  8,  8, 14, 12,  8,  9,  7,  7,  9,  9,  9,  9,  9,  1, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12,\n",
       "       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 14, 14, 14, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 14,  1,  1,  8,  1,  1,  1,  1,  1,  1,  1,  4,  4,  4,  7,  8,\n",
       "        4,  4,  4,  4,  4,  4,  4,  7,  7,  7,  8,  7,  7,  1,  7,  7,  7,\n",
       "        7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  9,  9,  9,  9,  9,  9,  9,  9,  7,  9,  9,  9,  9,  9,  9, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 14, 12,\n",
       "       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 14, 14, 14, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.71428571428571\n"
     ]
    }
   ],
   "source": [
    "print(get_acc(y_test, y_SVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
